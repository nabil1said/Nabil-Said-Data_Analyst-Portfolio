{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ew7BKCMWcgL3"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import concurrent.futures\n",
        "\n",
        "def extraire_infos_medline(fichier_path, nom_fichier_sans_ext):\n",
        "    with open(fichier_path, 'r', encoding='utf-8') as f:\n",
        "        contenu = f.read()\n",
        "\n",
        "    articles = re.split(r'\\n(?=PMID-)', contenu)\n",
        "    infos = []\n",
        "\n",
        "    for article in articles:\n",
        "        pmid = re.search(r'PMID-\\s*(\\d+)', article)\n",
        "        ti = re.search(r'TI\\s+-\\s+(.*?)(?=\\n[A-Z]{2,4} -|\\Z)', article, re.DOTALL)\n",
        "        ab = re.search(r'AB\\s+-\\s+(.*?)(?=\\n[A-Z]{2,4} -|\\Z)', article, re.DOTALL)\n",
        "        ad = re.findall(r'AD\\s+-\\s+(.*?)(?=\\s*\\n(?:FAU\\s*-\\s*|\\w{2,4}\\s*-\\s*)|\\Z)', article, re.DOTALL)\n",
        "        edat = re.search(r'EDAT-\\s*(\\d{4}/\\d{2}/\\d{2})', article)\n",
        "\n",
        "        infos.append({\n",
        "            'Nom du fichier': nom_fichier_sans_ext,\n",
        "            'PMID': pmid.group(1) if pmid else None,\n",
        "            'Titre (TI)': ti.group(1).replace('\\n', ' ').strip() if ti else None,\n",
        "            'Résumé (AB)': ab.group(1).replace('\\n', ' ').strip() if ab else None,\n",
        "            'Adresse (AD)': ' | '.join([a.replace('\\n', ' ').strip() for a in ad]) if ad else None,\n",
        "            'Date EDAT': edat.group(1) if edat else None\n",
        "        })\n",
        "\n",
        "    return infos\n",
        "\n",
        "def process_file(chemin_fichier):\n",
        "    nom_fichier_sans_ext = os.path.splitext(os.path.basename(chemin_fichier))[0]\n",
        "    infos = extraire_infos_medline(chemin_fichier, nom_fichier_sans_ext)\n",
        "    if infos:\n",
        "        df = pd.DataFrame(infos)\n",
        "        excel_path = os.path.join(excel_dir, nom_fichier_sans_ext + \".xlsx\")\n",
        "        df.to_excel(excel_path, index=False)\n",
        "        return excel_path\n",
        "    return None\n",
        "\n",
        "try:\n",
        "    # Étape 1 : Téléversement du ZIP\n",
        "    uploaded = files.upload()\n",
        "    zip_filename = list(uploaded.keys())[0]\n",
        "\n",
        "    # Étape 2 : Extraction dans un dossier temporaire\n",
        "    extract_dir = \"temp_extraction\"\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "\n",
        "    # Étape 3 : Recherche des fichiers .txt\n",
        "    fichiers_txt = [\n",
        "        os.path.join(root, file)\n",
        "        for root, _, files_in_dir in os.walk(extract_dir)\n",
        "        for file in files_in_dir\n",
        "        if file.endswith(\".txt\")\n",
        "    ]\n",
        "\n",
        "    if not fichiers_txt:\n",
        "        print(\"❌ Aucun fichier .txt trouvé dans le ZIP.\")\n",
        "    else:\n",
        "        print(f\"✅ {len(fichiers_txt)} fichier(s) .txt trouvé(s). Traitement en cours...\")\n",
        "\n",
        "        excel_dir = \"resultats_excel\"\n",
        "        os.makedirs(excel_dir, exist_ok=True)\n",
        "\n",
        "        # Utilisation de ThreadPoolExecutor pour le traitement parallèle\n",
        "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "            futures = [executor.submit(process_file, fichier) for fichier in fichiers_txt]\n",
        "            excel_files_paths = [future.result() for future in tqdm(concurrent.futures.as_completed(futures), total=len(fichiers_txt), desc=\"Traitement des fichiers\") if future.result() is not None]\n",
        "\n",
        "        # Étape 4 : Création du ZIP des fichiers Excel\n",
        "        zip_result_name = os.path.splitext(zip_filename)[0] + \"_excels.zip\"\n",
        "        with zipfile.ZipFile(zip_result_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "            for filepath in excel_files_paths:\n",
        "                if filepath:\n",
        "                    zipf.write(filepath, arcname=os.path.basename(filepath))\n",
        "\n",
        "        # Étape 5 : Téléchargement\n",
        "        print(f\"✅ Fichiers Excel générés : {len(excel_files_paths)}\")\n",
        "        files.download(zip_result_name)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Une erreur est survenue : {e}\")\n"
      ]
    }
  ]
}