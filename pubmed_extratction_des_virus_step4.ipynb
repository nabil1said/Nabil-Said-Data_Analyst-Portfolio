{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# üì¶ INSTALLATION\n",
        "!pip install flashtext openpyxl"
      ],
      "metadata": {
        "id": "gfvZW4h1pZFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df706d4-5a25-418e-86f5-daa281d35b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flashtext\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Building wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9300 sha256=38c28d8fa8e83afcac745c4a548a5e66f2be34d3d700a16b22eb31d66f46ce2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/20/47/f03dfa8a7239c54cbc44ff7389eefbf888d2c1873edaaec888\n",
            "Successfully built flashtext\n",
            "Installing collected packages: flashtext\n",
            "Successfully installed flashtext-2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìö IMPORTS\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "from flashtext import KeywordProcessor\n",
        "from tqdm import tqdm\n",
        "import concurrent.futures\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "def main():\n",
        "    # üì• T√âL√âVERSEMENT DES FICHIERS\n",
        "    print(\"‚û°Ô∏è T√©l√©versez le fichier ZIP contenant les fichiers .xlsx...\")\n",
        "    uploaded = files.upload()\n",
        "    zip_filename = list(uploaded.keys())[0]\n",
        "\n",
        "    print(\"‚û°Ô∏è T√©l√©versez le fichier Excel des taxons (colonnes: Virus, Variant, Genus, Family)...\")\n",
        "    uploaded = files.upload()\n",
        "    taxon_filename = list(uploaded.keys())[0]\n",
        "\n",
        "    # üìÇ EXTRACTION DU ZIP\n",
        "    input_dir = \"extracted_files\"\n",
        "    os.makedirs(input_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall(input_dir)\n",
        "\n",
        "    # üîç CHARGEMENT DES FICHIERS EXCEL\n",
        "    excel_files = [\n",
        "        os.path.join(root, file)\n",
        "        for root, _, files_ in os.walk(input_dir)\n",
        "        for file in files_\n",
        "        if file.lower().endswith(\".xlsx\")\n",
        "    ]\n",
        "    if not excel_files:\n",
        "        raise Exception(\"‚ùå Aucun fichier .xlsx trouv√© dans le dossier.\")\n",
        "\n",
        "    # üìÑ CHARGEMENT DES DONN√âES TAXONOMIQUES\n",
        "    df_taxons = pd.read_excel(taxon_filename, engine='openpyxl')\n",
        "    df_taxons.columns = df_taxons.columns.str.strip()\n",
        "\n",
        "    required_columns = {'Virus', 'Variant', 'Genus', 'Family'}\n",
        "    if not required_columns.issubset(df_taxons.columns):\n",
        "        missing = required_columns - set(df_taxons.columns)\n",
        "        raise ValueError(f\"‚ùå Colonnes manquantes dans le fichier taxons: {missing}\")\n",
        "\n",
        "    # üß† CR√âATION DES DICTIONNAIRES DE CORRESPONDANCE\n",
        "    dict_virus_variants = {}\n",
        "    dict_virus_genus = {}\n",
        "    dict_genus_family = {}\n",
        "\n",
        "    for row in df_taxons.itertuples(index=False):\n",
        "        virus = str(row.Virus).strip()\n",
        "        variants = [v.strip() for v in str(row.Variant).replace(\";\", \",\").split(\",\") if v.strip()]\n",
        "        dict_virus_variants[virus] = variants\n",
        "\n",
        "        genus = str(row.Genus).strip()\n",
        "        if genus and genus.lower() != 'nan':\n",
        "            dict_virus_genus[virus] = genus\n",
        "\n",
        "        family = str(row.Family).strip()\n",
        "        if genus and genus.lower() != 'nan' and family and family.lower() != 'nan':\n",
        "            dict_genus_family[genus] = family\n",
        "\n",
        "    # üîç INITIALISATION DES PROCESSEURS FLASHTEXT\n",
        "    kp_virus = KeywordProcessor(case_sensitive=False)\n",
        "    for virus, variants in dict_virus_variants.items():\n",
        "        for variant in variants:\n",
        "            kp_virus.add_keyword(variant, virus)\n",
        "        kp_virus.add_keyword(virus, virus)\n",
        "\n",
        "    kp_genus = KeywordProcessor(case_sensitive=False)\n",
        "    for virus, genus in dict_virus_genus.items():\n",
        "        kp_genus.add_keyword(virus, genus)\n",
        "        kp_genus.add_keyword(genus, genus)\n",
        "\n",
        "    kp_family = KeywordProcessor(case_sensitive=False)\n",
        "    for genus, family in dict_genus_family.items():\n",
        "        kp_family.add_keyword(genus, family)\n",
        "\n",
        "    # ‚öôÔ∏è FONCTIONS DE D√âTECTION\n",
        "    def detecter_virus(texte):\n",
        "        if pd.isna(texte):\n",
        "            return set()\n",
        "        found = kp_virus.extract_keywords(str(texte))\n",
        "        return set(found) if found else set()\n",
        "\n",
        "    def detecter_genus(texte):\n",
        "        if pd.isna(texte):\n",
        "            return set()\n",
        "        found = kp_genus.extract_keywords(str(texte))\n",
        "        return set(found) if found else set()\n",
        "\n",
        "    def detecter_famille(texte):\n",
        "        if pd.isna(texte):\n",
        "            return set()\n",
        "        found = kp_family.extract_keywords(str(texte))\n",
        "        return set(found) if found else set()\n",
        "\n",
        "    # ‚öôÔ∏è FONCTION DE TRAITEMENT D'UN FICHIER\n",
        "    def traiter_fichier(filepath):\n",
        "        try:\n",
        "            filename = os.path.basename(filepath)\n",
        "            print(f\"üîé Traitement de : {filename}\")\n",
        "\n",
        "            df = pd.read_excel(filepath, engine='openpyxl')\n",
        "            colonnes_requises = {\"Titre\", \"R√©sum√©\", \"Entities_bc5cdr\", \"Entities_bionlp\"}\n",
        "\n",
        "            if not colonnes_requises.issubset(df.columns):\n",
        "                missing = colonnes_requises - set(df.columns)\n",
        "                print(f\"‚ùå Colonnes manquantes dans {filename}: {missing}\")\n",
        "                return None\n",
        "\n",
        "            titre_resume = df[\"Titre\"].fillna(\"\") + \" \" + df[\"R√©sum√©\"].fillna(\"\")\n",
        "            entites_concat = df[\"Entities_bionlp\"].fillna(\"\") + \" \" + df[\"Entities_bc5cdr\"].fillna(\"\")\n",
        "\n",
        "            virus_detect√©s_liste = []\n",
        "            genus_par_d√©faut_liste = []\n",
        "\n",
        "            for t1, t2 in zip(titre_resume, entites_concat):\n",
        "                virus_set = detecter_virus(t1) | detecter_virus(t2)\n",
        "                if virus_set:\n",
        "                    virus_detect√©s_liste.append(\", \".join(sorted(virus_set)))\n",
        "                    genus_par_d√©faut_liste.append(\"\")\n",
        "                else:\n",
        "                    virus_detect√©s_liste.append(\"\")\n",
        "                    genus_alt = detecter_genus(t1)\n",
        "                    genus_par_d√©faut_liste.append(\", \".join(sorted(genus_alt)) if genus_alt else \"\")\n",
        "\n",
        "            df[\"Virus_detect√©s\"] = virus_detect√©s_liste\n",
        "            df[\"Genus_par_d√©faut\"] = genus_par_d√©faut_liste\n",
        "\n",
        "            df[\"Genus_detect√©s\"] = df[\"Virus_detect√©s\"].apply(\n",
        "                lambda viruses: \", \".join(sorted({\n",
        "                    dict_virus_genus.get(virus.strip(), \"\")\n",
        "                    for virus in viruses.split(\",\")\n",
        "                    if virus.strip() in dict_virus_genus\n",
        "                })) if viruses.strip() else \"\"\n",
        "            )\n",
        "\n",
        "            df[\"Genus_detect√©s\"] = df.apply(\n",
        "                lambda row: row[\"Genus_detect√©s\"] if row[\"Genus_detect√©s\"] else row[\"Genus_par_d√©faut\"],\n",
        "                axis=1\n",
        "            )\n",
        "\n",
        "            df[\"Familles_detect√©es\"] = df[\"Genus_detect√©s\"].apply(\n",
        "                lambda genera: \", \".join(sorted({\n",
        "                    dict_genus_family.get(genus.strip(), \"\")\n",
        "                    for genus in genera.split(\",\")\n",
        "                    if genus.strip() in dict_genus_family\n",
        "                })) if pd.notna(genera) else \"\"\n",
        "            )\n",
        "\n",
        "            # Fallback pour pr√©sence virus par regex si aucune d√©tection pr√©c√©dente\n",
        "            df[\"presence_virus\"] = [\n",
        "                \", \".join(re.findall(r'\\b[\\w\\-]*virus\\b', txt, re.IGNORECASE))\n",
        "                if (not v or v.strip() == \"\") and (not g or g.strip() == \"\") and re.search(r'\\b[\\w\\-]*virus\\b', txt, re.IGNORECASE)\n",
        "                else \"\"\n",
        "                for v, g, txt in zip(df[\"Virus_detect√©s\"], df[\"Genus_detect√©s\"], titre_resume)\n",
        "            ]\n",
        "\n",
        "            return df, filename\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erreur lors du traitement de {filepath}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    # üìÇ DOSSIER DE SORTIE\n",
        "    output_dir = \"fichiers_des_virus\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # üîÅ TRAITEMENT DES FICHIERS EN PARALL√àLE\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        futures = {executor.submit(traiter_fichier, filepath): filepath for filepath in excel_files}\n",
        "\n",
        "        for future in tqdm(concurrent.futures.as_completed(futures),\n",
        "                          total=len(futures),\n",
        "                          desc=\"üîÑ Traitement des fichiers\"):\n",
        "            result = future.result()\n",
        "            if result is not None:\n",
        "                df, filename = result\n",
        "                output_path = os.path.join(output_dir, filename)\n",
        "                df.to_excel(output_path, index=False, engine='openpyxl')\n",
        "                print(f\"‚úÖ Sauvegard√© : {output_path}\")\n",
        "\n",
        "    # üì¶ COMPRESSION EN FICHIER ZIP\n",
        "    zip_output_path = os.path.join(os.getcwd(), \"fichiers_virus_annot√©s\")\n",
        "    shutil.make_archive(zip_output_path, \"zip\", output_dir)\n",
        "\n",
        "    # üì§ T√âL√âCHARGEMENT DU ZIP\n",
        "    files.download(f\"{zip_output_path}.zip\")\n",
        "    print(f\"üì¶ Archive ZIP g√©n√©r√©e et pr√™te √† √™tre t√©l√©charg√©e: {zip_output_path}.zip\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sgZZ4gsl2Jik",
        "outputId": "cd271325-9f43-4e65-cb29-502f94b051e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚û°Ô∏è T√©l√©versez le fichier ZIP contenant les fichiers .xlsx...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fc920862-3e1c-4a6b-bbfd-263cd13b8f60\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fc920862-3e1c-4a6b-bbfd-263cd13b8f60\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resultats_pays_detectes_step3.zip to resultats_pays_detectes_step3.zip\n",
            "‚û°Ô∏è T√©l√©versez le fichier Excel des taxons (colonnes: Virus, Variant, Genus, Family)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6696f83c-b886-41dd-aa20-0a2b4b8c2b62\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6696f83c-b886-41dd-aa20-0a2b4b8c2b62\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving nouveau_liste.xlsx to nouveau_liste.xlsx\n",
            "üîé Traitement de : Sudan_entites.xlsx\n",
            "üîé Traitement de : Guinea_entites.xlsx\n",
            "üîé Traitement de : Zambia_entites.xlsx\n",
            "üîé Traitement de : Rwanda_entites.xlsx\n",
            "üîé Traitement de : Niger_entites.xlsx\n",
            "üîé Traitement de : Lesotho_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:   0%|          | 0/54 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîé Traitement de : Morocco_entites.xlsx\n",
            "üîé Traitement de : Cameroon_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:   2%|‚ñè         | 1/54 [00:02<01:57,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Lesotho_entites.xlsx\n",
            "üîé Traitement de : Gambia_entites.xlsx\n",
            "üîé Traitement de : Ivory Coast_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:   4%|‚ñé         | 2/54 [00:04<01:50,  2.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Niger_entites.xlsx\n",
            "üîé Traitement de : Zimbabwe_entites.xlsx\n",
            "üîé Traitement de : South Sudan_entites.xlsx\n",
            "üîé Traitement de : Chad_entites.xlsx\n",
            "üîé Traitement de : Gabon_entites.xlsx\n",
            "üîé Traitement de : Nigeria_entites.xlsx\n",
            "üîé Traitement de : Sierra Leone_entites.xlsx\n",
            "üîé Traitement de : Seychelles_entites.xlsx\n",
            "üîé Traitement de : Mozambique_entites.xlsx\n",
            "üîé Traitement de : South Africa1_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:   6%|‚ñå         | 3/54 [00:11<03:39,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîé Traitement de : Somalia_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Rwanda_entites.xlsx\n",
            "üîé Traitement de : S‚ïûo Tom√© and Pr√≠ncipe_entites.xlsx\n",
            "üîé Traitement de : Benin_entites.xlsx\n",
            "üîé Traitement de : Guine Bissau_entites.xlsx\n",
            "üîé Traitement de : Tanzania_entites.xlsx\n",
            "üîé Traitement de : Equatorial Guinea_entites.xlsx\n",
            "üîé Traitement de : Uganda_entites.xlsx\n",
            "üîé Traitement de : Egypt_entites.xlsx\n",
            "üîé Traitement de : Madagascar_entites.xlsx\n",
            "üîé Traitement de : Congo_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:   7%|‚ñã         | 4/54 [00:17<04:08,  4.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Guinea_entites.xlsx\n",
            "üîé Traitement de : Burundi_entites.xlsx\n",
            "üîé Traitement de : Ethiopia_entites.xlsx\n",
            "üîé Traitement de : Eritrea_entites.xlsx\n",
            "üîé Traitement de : Algeria_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:   9%|‚ñâ         | 5/54 [00:22<04:12,  5.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Sudan_entites.xlsx\n",
            "üîé Traitement de : Djibouti_entites.xlsx\n",
            "üîé Traitement de : Botswana_entites.xlsx\n",
            "üîé Traitement de : Mauritania_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  11%|‚ñà         | 6/54 [00:25<03:27,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Gambia_entites.xlsx\n",
            "üîé Traitement de : Libya_entites.xlsx\n",
            "üîé Traitement de : South Africa_entites.xlsx\n",
            "üîé Traitement de : Mali_entites.xlsx\n",
            "üîé Traitement de : Liberia_entites.xlsx\n",
            "üîé Traitement de : Malawi_entites.xlsx\n",
            "üîé Traitement de : Central African Republic_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  13%|‚ñà‚ñé        | 7/54 [00:39<05:46,  7.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîé Traitement de : Comoros_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Zambia_entites.xlsx\n",
            "üîé Traitement de : Kenya_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  15%|‚ñà‚ñç        | 8/54 [00:39<04:00,  5.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/South Sudan_entites.xlsx\n",
            "üîé Traitement de : Ghana_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  17%|‚ñà‚ñã        | 9/54 [00:41<03:02,  4.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Chad_entites.xlsx\n",
            "üîé Traitement de : Tunisia_entites.xlsx\n",
            "üîé Traitement de : Burkina Faso_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  19%|‚ñà‚ñä        | 10/54 [00:46<03:10,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Ivory Coast_entites.xlsx\n",
            "üîé Traitement de : Mauritius_entites.xlsx\n",
            "üîé Traitement de : Angola_entites.xlsx\n",
            "üîé Traitement de : Cabo Verde_entites.xlsx\n",
            "üîé Traitement de : Eswatini_entites.xlsx\n",
            "üîé Traitement de : Namibia_entites.xlsx\n",
            "üîé Traitement de : Togo_entites.xlsx\n",
            "üîé Traitement de : Senegal_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  20%|‚ñà‚ñà        | 11/54 [00:55<04:11,  5.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Morocco_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  22%|‚ñà‚ñà‚ñè       | 12/54 [00:55<02:56,  4.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Seychelles_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  24%|‚ñà‚ñà‚ñç       | 13/54 [01:02<03:26,  5.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Gabon_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  26%|‚ñà‚ñà‚ñå       | 14/54 [01:09<03:38,  5.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Cameroon_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÑ Traitement des fichiers:  33%|‚ñà‚ñà‚ñà‚ñé      | 18/54 [01:09<01:02,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Sierra Leone_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/S‚ïûo Tom√© and Pr√≠ncipe_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Somalia_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Benin_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  35%|‚ñà‚ñà‚ñà‚ñå      | 19/54 [01:09<00:48,  1.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Guine Bissau_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  37%|‚ñà‚ñà‚ñà‚ñã      | 20/54 [01:10<00:44,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Zimbabwe_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Equatorial Guinea_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  41%|‚ñà‚ñà‚ñà‚ñà      | 22/54 [01:11<00:28,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Mozambique_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 23/54 [01:11<00:23,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Madagascar_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 24/54 [01:13<00:28,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Tanzania_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Burundi_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 26/54 [01:14<00:21,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Congo_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Eritrea_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÑ Traitement des fichiers:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 31/54 [01:14<00:07,  3.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Algeria_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Djibouti_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Botswana_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Mauritania_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Libya_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 33/54 [01:19<00:19,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Nigeria_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 34/54 [01:23<00:28,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/South Africa1_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 35/54 [01:23<00:22,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Mali_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÑ Traitement des fichiers:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 37/54 [01:26<00:21,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Uganda_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Liberia_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 39/54 [01:26<00:11,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Comoros_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Central African Republic_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 40/54 [01:30<00:18,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Ethiopia_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 41/54 [01:31<00:16,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Malawi_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 42/54 [01:31<00:12,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Burkina Faso_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÑ Traitement des fichiers:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 45/54 [01:33<00:06,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Ghana_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Angola_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Cabo Verde_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Eswatini_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 47/54 [01:34<00:04,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Mauritius_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÑ Traitement des fichiers:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 49/54 [01:35<00:02,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Tunisia_entites.xlsx\n",
            "‚úÖ Sauvegard√© : fichiers_des_virus/Namibia_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 50/54 [01:35<00:01,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Togo_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 51/54 [01:36<00:01,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Senegal_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 52/54 [01:39<00:02,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Kenya_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüîÑ Traitement des fichiers:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 53/54 [01:47<00:03,  3.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/Egypt_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÑ Traitement des fichiers: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54/54 [01:52<00:00,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sauvegard√© : fichiers_des_virus/South Africa_entites.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_34abb54c-a7ca-4789-b620-c695d68aacff\", \"fichiers_virus_annot\\u00e9s.zip\", 85939499)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Archive ZIP g√©n√©r√©e et pr√™te √† √™tre t√©l√©charg√©e: /content/fichiers_virus_annot√©s.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìö IMPORTS\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "from flashtext import KeywordProcessor\n",
        "from tqdm import tqdm\n",
        "import concurrent.futures\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "def main():\n",
        "    # üì• T√âL√âVERSEMENT DES FICHIERS\n",
        "    print(\"‚ûûÔ∏è T√©l√©versez le fichier ZIP contenant les fichiers .xlsx...\")\n",
        "    uploaded = files.upload()\n",
        "    zip_filename = list(uploaded.keys())[0]\n",
        "\n",
        "    print(\"‚ûûÔ∏è T√©l√©versez le fichier Excel des taxons (colonnes: Virus, Variant, Genus, Family)...\")\n",
        "    uploaded = files.upload()\n",
        "    taxon_filename = list(uploaded.keys())[0]\n",
        "\n",
        "    # üìÇ EXTRACTION DU ZIP\n",
        "    input_dir = \"extracted_files\"\n",
        "    os.makedirs(input_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall(input_dir)\n",
        "\n",
        "    # üîç CHARGEMENT DES FICHIERS EXCEL\n",
        "    excel_files = [\n",
        "        os.path.join(root, file)\n",
        "        for root, _, files_ in os.walk(input_dir)\n",
        "        for file in files_\n",
        "        if file.lower().endswith(\".xlsx\")\n",
        "    ]\n",
        "    if not excel_files:\n",
        "        raise Exception(\"‚ùå Aucun fichier .xlsx trouv√© dans le dossier.\")\n",
        "\n",
        "    # üìÑ CHARGEMENT DES DONN√âES TAXONOMIQUES\n",
        "    df_taxons = pd.read_excel(taxon_filename, engine='openpyxl')\n",
        "    df_taxons.columns = df_taxons.columns.str.strip()\n",
        "\n",
        "    required_columns = {'Virus', 'Variant', 'Genus', 'Family'}\n",
        "    if not required_columns.issubset(df_taxons.columns):\n",
        "        missing = required_columns - set(df_taxons.columns)\n",
        "        raise ValueError(f\"‚ùå Colonnes manquantes dans le fichier taxons: {missing}\")\n",
        "\n",
        "    dict_virus_variants = {}\n",
        "    for row in df_taxons.itertuples(index=False):\n",
        "        virus = str(row.Virus).strip()\n",
        "        variants = [v.strip() for v in str(row.Variant).replace(\";\", \",\").split(\",\") if v.strip()]\n",
        "        dict_virus_variants[virus] = variants\n",
        "\n",
        "    dict_virus_genus = {}\n",
        "    for row in df_taxons.itertuples(index=False):\n",
        "        virus = str(row.Virus).strip()\n",
        "        genus = str(row.Genus).strip()\n",
        "        if genus and genus.lower() != 'nan':\n",
        "            dict_virus_genus[virus] = genus\n",
        "\n",
        "    dict_genus_family = {}\n",
        "    for row in df_taxons.itertuples(index=False):\n",
        "        genus = str(row.Genus).strip()\n",
        "        family = str(row.Family).strip()\n",
        "        if genus and genus.lower() != 'nan' and family and family.lower() != 'nan':\n",
        "            dict_genus_family[genus] = family\n",
        "\n",
        "    kp_virus = KeywordProcessor(case_sensitive=False)\n",
        "    for virus, variants in dict_virus_variants.items():\n",
        "        for variant in variants:\n",
        "            kp_virus.add_keyword(variant, virus)\n",
        "        kp_virus.add_keyword(virus, virus)\n",
        "\n",
        "    kp_genus = KeywordProcessor(case_sensitive=False)\n",
        "    for virus, genus in dict_virus_genus.items():\n",
        "        kp_genus.add_keyword(virus, genus)\n",
        "\n",
        "    kp_family = KeywordProcessor(case_sensitive=False)\n",
        "    for genus, family in dict_genus_family.items():\n",
        "        kp_family.add_keyword(genus, family)\n",
        "\n",
        "    def detecter_virus(texte):\n",
        "        if pd.isna(texte):\n",
        "            return set()\n",
        "        found = kp_virus.extract_keywords(str(texte))\n",
        "        return set(found) if found else set()\n",
        "\n",
        "    def detecter_genus(texte):\n",
        "        if pd.isna(texte):\n",
        "            return set()\n",
        "        found = kp_genus.extract_keywords(str(texte))\n",
        "        return set(found) if found else set()\n",
        "\n",
        "    def detecter_famille(texte):\n",
        "        if pd.isna(texte):\n",
        "            return set()\n",
        "        found = kp_family.extract_keywords(str(texte))\n",
        "        return set(found) if found else set()\n",
        "\n",
        "    def traiter_fichier(filepath):\n",
        "        try:\n",
        "            filename = os.path.basename(filepath)\n",
        "            print(f\"üîé Traitement de : {filename}\")\n",
        "\n",
        "            df = pd.read_excel(filepath, engine='openpyxl')\n",
        "            colonnes_requises = {\"Titre\", \"R√©sum√©\", \"Entities_bc5cdr\", \"Entities_bionlp\"}\n",
        "            if not colonnes_requises.issubset(df.columns):\n",
        "                missing = colonnes_requises - set(df.columns)\n",
        "                print(f\"‚ùå Colonnes manquantes dans {filename}: {missing}\")\n",
        "                return None\n",
        "\n",
        "            titre_resume = df[\"Titre\"].fillna(\"\") + \" \" + df[\"R√©sum√©\"].fillna(\"\")\n",
        "            df[\"titre_resume\"]=df[\"Titre\"].fillna(\"\") + \" \" + df[\"R√©sum√©\"].fillna(\"\")\n",
        "            entites_concat = df[\"Entities_bionlp\"].fillna(\"\") + \" \" + df[\"Entities_bc5cdr\"].fillna(\"\")\n",
        "\n",
        "            df[\"Virus_detect√©s\"] = [\n",
        "                \", \".join(sorted(detecter_virus(t1) | detecter_virus(t2)))\n",
        "                for t1, t2 in zip(titre_resume, entites_concat)\n",
        "            ]\n",
        "\n",
        "            df[\"Genus_detect√©s\"] = df[\"Virus_detect√©s\"].apply(\n",
        "                lambda viruses: \", \".join(sorted({\n",
        "                    dict_virus_genus.get(virus.strip(), \"\")\n",
        "                    for virus in viruses.split(\",\")\n",
        "                    if virus.strip() in dict_virus_genus\n",
        "                })) if pd.notna(viruses) else \"\"\n",
        "            )\n",
        "\n",
        "            df[\"Familles_detect√©es\"] = df[\"Genus_detect√©s\"].apply(\n",
        "                lambda genera: \", \".join(sorted({\n",
        "                    dict_genus_family.get(genus.strip(), \"\")\n",
        "                    for genus in genera.split(\",\")\n",
        "                    if genus.strip() in dict_genus_family\n",
        "                })) if pd.notna(genera) else \"\"\n",
        "            )\n",
        "\n",
        "            df[\"presence_virus\"] = [\n",
        "                  \", \".join(re.findall(r'\\b[\\w\\-]*virus\\b', txt, re.IGNORECASE))\n",
        "                  if (not v or v.strip() == \"\") and (not g or g.strip() == \"\") and re.search(r'\\b[\\w\\-]*virus\\b', txt, re.IGNORECASE)\n",
        "                  else \"\"\n",
        "                  for v, g, txt in zip(df[\"Virus_detect√©s\"], df[\"Genus_detect√©s\"], titre_resume)\n",
        "              ]\n",
        "\n",
        "            return df, filename\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erreur lors du traitement de {filepath}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    output_dir = \"fichiers_des_virus\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        futures = {executor.submit(traiter_fichier, filepath): filepath for filepath in excel_files}\n",
        "\n",
        "        for future in tqdm(concurrent.futures.as_completed(futures),\n",
        "                          total=len(futures),\n",
        "                          desc=\"üîÑ Traitement des fichiers\"):\n",
        "            result = future.result()\n",
        "            if result is not None:\n",
        "                df, filename = result\n",
        "                output_path = os.path.join(output_dir, filename)\n",
        "                df.to_excel(output_path, index=False, engine='openpyxl')\n",
        "                print(f\"‚úÖ Sauvegard√© : {output_path}\")\n",
        "\n",
        "    zip_output_path = os.path.join(os.getcwd(), \"fichiers_virus_annot√©s\")\n",
        "    shutil.make_archive(zip_output_path, \"zip\", output_dir)\n",
        "\n",
        "    files.download(f\"{zip_output_path}.zip\")\n",
        "    print(f\"üì¶ Archive ZIP g√©n√©r√©e et pr√™te √† √™tre t√©l√©charg√©e: {zip_output_path}.zip\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "zhqWR9-aonwk",
        "outputId": "7ab6a9e1-e449-4ce2-99df-3e74da457351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ûûÔ∏è T√©l√©versez le fichier ZIP contenant les fichiers .xlsx...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-67abb13b-256d-43f8-aae9-65edd2783908\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-67abb13b-256d-43f8-aae9-65edd2783908\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-704220893.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3-704220893.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# üì• T√âL√âVERSEMENT DES FICHIERS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚ûûÔ∏è T√©l√©versez le fichier ZIP contenant les fichiers .xlsx...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mzip_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìö IMPORTS\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "from flashtext import KeywordProcessor\n",
        "from tqdm import tqdm\n",
        "import concurrent.futures\n",
        "import shutil\n",
        "\n",
        "def main():\n",
        "    # üì• T√âL√âVERSEMENT DES FICHIERS\n",
        "    print(\"‚û°Ô∏è T√©l√©versez le fichier ZIP contenant les fichiers .xlsx...\")\n",
        "    uploaded = files.upload()\n",
        "    zip_filename = list(uploaded.keys())[0]\n",
        "\n",
        "    print(\"‚û°Ô∏è T√©l√©versez le fichier Excel des taxons (colonnes: Virus, Variant, Genus, Family)...\")\n",
        "    uploaded = files.upload()\n",
        "    taxon_filename = list(uploaded.keys())[0]\n",
        "\n",
        "    # üìÇ EXTRACTION DU ZIP\n",
        "    input_dir = \"extracted_files\"\n",
        "    os.makedirs(input_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall(input_dir)\n",
        "\n",
        "    # üîç CHARGEMENT DES FICHIERS EXCEL\n",
        "    excel_files = [\n",
        "        os.path.join(root, file)\n",
        "        for root, _, files_ in os.walk(input_dir)\n",
        "        for file in files_\n",
        "        if file.lower().endswith(\".xlsx\")\n",
        "    ]\n",
        "    if not excel_files:\n",
        "        raise Exception(\"‚ùå Aucun fichier .xlsx trouv√© dans le dossier.\")\n",
        "\n",
        "    # üìÑ CHARGEMENT DES DONN√âES TAXONOMIQUES\n",
        "    df_taxons = pd.read_excel(taxon_filename, engine='openpyxl')\n",
        "    df_taxons.columns = df_taxons.columns.str.strip()\n",
        "\n",
        "    # V√©rification des colonnes n√©cessaires\n",
        "    required_columns = {'Virus', 'Variant', 'Genus', 'Family'}\n",
        "    if not required_columns.issubset(df_taxons.columns):\n",
        "        missing = required_columns - set(df_taxons.columns)\n",
        "        raise ValueError(f\"‚ùå Colonnes manquantes dans le fichier taxons: {missing}\")\n",
        "\n",
        "    # üß† CR√âATION DES DICTIONNAIRES DE CORRESPONDANCE\n",
        "    dict_virus_variants = {}\n",
        "    for row in df_taxons.itertuples(index=False):\n",
        "        virus = str(row.Virus).strip()\n",
        "        variants = [v.strip() for v in str(row.Variant).replace(\";\", \",\").split(\",\") if v.strip()]\n",
        "        dict_virus_variants[virus] = variants\n",
        "\n",
        "    dict_virus_genus = {}\n",
        "    for row in df_taxons.itertuples(index=False):\n",
        "        virus = str(row.Virus).strip()\n",
        "        genus = str(row.Genus).strip()\n",
        "        if genus and genus.lower() != 'nan':\n",
        "            dict_virus_genus[virus] = genus\n",
        "\n",
        "    dict_genus_family = {}\n",
        "    for row in df_taxons.itertuples(index=False):\n",
        "        genus = str(row.Genus).strip()\n",
        "        family = str(row.Family).strip()\n",
        "        if genus and genus.lower() != 'nan' and family and family.lower() != 'nan':\n",
        "            dict_genus_family[genus] = family\n",
        "\n",
        "    # üîç INITIALISATION DES PROCESSEURS FLASHTEXT\n",
        "    kp_virus = KeywordProcessor(case_sensitive=False)\n",
        "    for virus, variants in dict_virus_variants.items():\n",
        "        for variant in variants:\n",
        "            kp_virus.add_keyword(variant, virus)\n",
        "        kp_virus.add_keyword(virus, virus)\n",
        "\n",
        "    kp_genus = KeywordProcessor(case_sensitive=False)\n",
        "    for virus, genus in dict_virus_genus.items():\n",
        "        kp_genus.add_keyword(virus, genus)\n",
        "        kp_genus.add_keyword(genus, genus)\n",
        "\n",
        "    kp_family = KeywordProcessor(case_sensitive=False)\n",
        "    for genus, family in dict_genus_family.items():\n",
        "        kp_family.add_keyword(genus, family)\n",
        "\n",
        "    # ‚öôÔ∏è FONCTIONS DE D√âTECTION\n",
        "    def detecter_virus(texte):\n",
        "        if pd.isna(texte):\n",
        "            return set()\n",
        "        found = kp_virus.extract_keywords(str(texte))\n",
        "        return set(found) if found else set()\n",
        "\n",
        "    def detecter_genus(texte):\n",
        "        if pd.isna(texte):\n",
        "            return set()\n",
        "        found = kp_genus.extract_keywords(str(texte))\n",
        "        return set(found) if found else set()\n",
        "\n",
        "    def detecter_famille(texte):\n",
        "        if pd.isna(texte):\n",
        "            return set()\n",
        "        found = kp_family.extract_keywords(str(texte))\n",
        "        return set(found) if found else set()\n",
        "\n",
        "    # ‚öôÔ∏è FONCTION DE TRAITEMENT D'UN FICHIER\n",
        "    def traiter_fichier(filepath):\n",
        "        try:\n",
        "            filename = os.path.basename(filepath)\n",
        "            print(f\"üîé Traitement de : {filename}\")\n",
        "\n",
        "            df = pd.read_excel(filepath, engine='openpyxl')\n",
        "            colonnes_requises = {\"Titre\", \"R√©sum√©\", \"Entities_bc5cdr\", \"Entities_bionlp\"}\n",
        "\n",
        "            if not colonnes_requises.issubset(df.columns):\n",
        "                missing = colonnes_requises - set(df.columns)\n",
        "                print(f\"‚ùå Colonnes manquantes dans {filename}: {missing}\")\n",
        "                return None\n",
        "\n",
        "            titre_resume = df[\"Titre\"].fillna(\"\") + \" \" + df[\"R√©sum√©\"].fillna(\"\")\n",
        "            entites_concat = df[\"Entities_bionlp\"].fillna(\"\") + \" \" + df[\"Entities_bc5cdr\"].fillna(\"\")\n",
        "\n",
        "            # D√©tection virus et genus fallback\n",
        "            virus_detect√©s_liste = []\n",
        "            genus_par_d√©faut_liste = []\n",
        "\n",
        "            for t1, t2 in zip(titre_resume, entites_concat):\n",
        "                virus_set = detecter_virus(t1) | detecter_virus(t2)\n",
        "                if virus_set:\n",
        "                    virus_detect√©s_liste.append(\", \".join(sorted(virus_set)))\n",
        "                    genus_par_d√©faut_liste.append(\"\")\n",
        "                else:\n",
        "                    virus_detect√©s_liste.append(\"\")\n",
        "                    genus_alt = detecter_genus(t1)\n",
        "                    genus_par_d√©faut_liste.append(\", \".join(sorted(genus_alt)) if genus_alt else \"\")\n",
        "\n",
        "            df[\"Virus_detect√©s\"] = virus_detect√©s_liste\n",
        "            df[\"Genus_par_d√©faut\"] = genus_par_d√©faut_liste\n",
        "\n",
        "            # D√©tection des genres\n",
        "            df[\"Genus_detect√©s\"] = df[\"Virus_detect√©s\"].apply(\n",
        "                lambda viruses: \", \".join(sorted({\n",
        "                    dict_virus_genus.get(virus.strip(), \"\")\n",
        "                    for virus in viruses.split(\",\")\n",
        "                    if virus.strip() in dict_virus_genus\n",
        "                })) if viruses.strip() else \"\"\n",
        "            )\n",
        "\n",
        "            # Si vide, utiliser genus d√©tect√© directement\n",
        "            df[\"Genus_detect√©s\"] = df.apply(\n",
        "                lambda row: row[\"Genus_detect√©s\"] if row[\"Genus_detect√©s\"] else row[\"Genus_par_d√©faut\"],\n",
        "                axis=1\n",
        "            )\n",
        "\n",
        "            # D√©tection des familles\n",
        "            df[\"Familles_detect√©es\"] = df[\"Genus_detect√©s\"].apply(\n",
        "                lambda genera: \", \".join(sorted({\n",
        "                    dict_genus_family.get(genus.strip(), \"\")\n",
        "                    for genus in genera.split(\",\")\n",
        "                    if genus.strip() in dict_genus_family\n",
        "                })) if pd.notna(genera) else \"\"\n",
        "            )\n",
        "\n",
        "            return df, filename\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erreur lors du traitement de {filepath}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    # üìÇ DOSSIER DE SORTIE\n",
        "    output_dir = \"fichiers_des_virus\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # üîÅ TRAITEMENT DES FICHIERS EN PARALL√àLE\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        futures = {executor.submit(traiter_fichier, filepath): filepath for filepath in excel_files}\n",
        "\n",
        "        for future in tqdm(concurrent.futures.as_completed(futures),\n",
        "                          total=len(futures),\n",
        "                          desc=\"üîÑ Traitement des fichiers\"):\n",
        "            result = future.result()\n",
        "            if result is not None:\n",
        "                df, filename = result\n",
        "                output_path = os.path.join(output_dir, filename)\n",
        "                df.to_excel(output_path, index=False, engine='openpyxl')\n",
        "                print(f\"‚úÖ Sauvegard√© : {output_path}\")\n",
        "\n",
        "    # üì¶ COMPRESSION EN FICHIER ZIP\n",
        "    zip_output_path = os.path.join(os.getcwd(), \"fichiers_virus_annot√©s\")\n",
        "    shutil.make_archive(zip_output_path, \"zip\", output_dir)\n",
        "\n",
        "    # üì§ T√âL√âCHARGEMENT DU ZIP\n",
        "    files.download(f\"{zip_output_path}.zip\")\n",
        "    print(f\"üì¶ Archive ZIP g√©n√©r√©e et pr√™te √† √™tre t√©l√©charg√©e: {zip_output_path}.zip\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "WfUrCfUojwX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##optimie le  pour le  multiprocessing\n"
      ],
      "metadata": {
        "id": "JW_NmX-MiJKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìö IMPORTS\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "from flashtext import KeywordProcessor\n",
        "from tqdm import tqdm\n",
        "import concurrent.futures\n",
        "import shutil\n",
        "\n",
        "def main():\n",
        "    # üì• T√âL√âVERSEMENT DES FICHIERS\n",
        "    print(\"‚û°Ô∏è T√©l√©versez le fichier ZIP contenant les fichiers .xlsx...\")\n",
        "    uploaded = files.upload()\n",
        "    zip_filename = list(uploaded.keys())[0]\n",
        "\n",
        "    print(\"‚û°Ô∏è T√©l√©versez le fichier Excel des taxons (colonnes: Virus, Variant, Genus, Family)...\")\n",
        "    uploaded = files.upload()\n",
        "    taxon_filename = list(uploaded.keys())[0]\n",
        "\n",
        "    # üìÇ EXTRACTION DU ZIP\n",
        "    input_dir = \"extracted_files\"\n",
        "    os.makedirs(input_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall(input_dir)\n",
        "\n",
        "    # üîç CHARGEMENT DES FICHIERS EXCEL\n",
        "    excel_files = [\n",
        "        os.path.join(root, file)\n",
        "        for root, _, files_ in os.walk(input_dir)\n",
        "        for file in files_\n",
        "        if file.lower().endswith(\".xlsx\")\n",
        "    ]\n",
        "    if not excel_files:\n",
        "        raise Exception(\"‚ùå Aucun fichier .xlsx trouv√© dans le dossier.\")\n",
        "\n",
        "    # üìÑ CHARGEMENT DES DONN√âES TAXONOMIQUES\n",
        "    df_taxons = pd.read_excel(taxon_filename, engine='openpyxl')\n",
        "    df_taxons.columns = df_taxons.columns.str.strip()\n",
        "\n",
        "    # V√©rification des colonnes n√©cessaires\n",
        "    required_columns = {'Virus', 'Variant', 'Genus', 'Family'}\n",
        "    if not required_columns.issubset(df_taxons.columns):\n",
        "        missing = required_columns - set(df_taxons.columns)\n",
        "        raise ValueError(f\"‚ùå Colonnes manquantes dans le fichier taxons: {missing}\")\n",
        "\n",
        "    # üß† CR√âATION DES DICTIONNAIRES DE CORRESPONDANCE\n",
        "    # Dictionnaire virus -> variants\n",
        "    dict_virus_variants = {}\n",
        "    for row in df_taxons.itertuples(index=False):\n",
        "        virus = str(row.Virus).strip()\n",
        "        variants = [v.strip() for v in str(row.Variant).replace(\";\", \",\").split(\",\") if v.strip()]\n",
        "        dict_virus_variants[virus] = variants\n",
        "\n",
        "    # Dictionnaire virus -> genus\n",
        "    dict_virus_genus = {}\n",
        "    for row in df_taxons.itertuples(index=False):\n",
        "        virus = str(row.Virus).strip()\n",
        "        genus = str(row.Genus).strip()\n",
        "        if genus and genus.lower() != 'nan':\n",
        "            dict_virus_genus[virus] = genus\n",
        "\n",
        "    # Dictionnaire genus -> family\n",
        "    dict_genus_family = {}\n",
        "    for row in df_taxons.itertuples(index=False):\n",
        "        genus = str(row.Genus).strip()\n",
        "        family = str(row.Family).strip()\n",
        "        if genus and genus.lower() != 'nan' and family and family.lower() != 'nan':\n",
        "            dict_genus_family[genus] = family\n",
        "\n",
        "    # üîç INITIALISATION DES PROCESSEURS FLASHTEXT\n",
        "    # Pour les variants de virus\n",
        "    kp_virus = KeywordProcessor(case_sensitive=False)\n",
        "    for virus, variants in dict_virus_variants.items():\n",
        "        for variant in variants:\n",
        "            kp_virus.add_keyword(variant, virus)\n",
        "        # Ajouter aussi le nom du virus lui-m√™me\n",
        "        kp_virus.add_keyword(virus, virus)\n",
        "\n",
        "    # Pour les genres\n",
        "    kp_genus = KeywordProcessor(case_sensitive=False)\n",
        "    for virus, genus in dict_virus_genus.items():\n",
        "        kp_genus.add_keyword(virus, genus)\n",
        "\n",
        "    # Pour les familles\n",
        "    kp_family = KeywordProcessor(case_sensitive=False)\n",
        "    for genus, family in dict_genus_family.items():\n",
        "        kp_family.add_keyword(genus, family)\n",
        "\n",
        "    # ‚öôÔ∏è FONCTIONS DE D√âTECTION\n",
        "    def detecter_virus(texte):\n",
        "        if pd.isna(texte):\n",
        "            return set()\n",
        "        found = kp_virus.extract_keywords(str(texte))\n",
        "        return set(found) if found else set()\n",
        "\n",
        "    def detecter_genus(texte):\n",
        "        if pd.isna(texte):\n",
        "            return set()\n",
        "        found = kp_genus.extract_keywords(str(texte))\n",
        "        return set(found) if found else set()\n",
        "\n",
        "    def detecter_famille(texte):\n",
        "        if pd.isna(texte):\n",
        "            return set()\n",
        "        found = kp_family.extract_keywords(str(texte))\n",
        "        return set(found) if found else set()\n",
        "\n",
        "    # ‚öôÔ∏è FONCTION DE TRAITEMENT D'UN FICHIER\n",
        "    def traiter_fichier(filepath):\n",
        "        try:\n",
        "            filename = os.path.basename(filepath)\n",
        "            print(f\"üîé Traitement de : {filename}\")\n",
        "\n",
        "            df = pd.read_excel(filepath, engine='openpyxl')\n",
        "            colonnes_requises = {\"Titre\", \"R√©sum√©\", \"Entities_bc5cdr\", \"Entities_bionlp\"}\n",
        "\n",
        "            if not colonnes_requises.issubset(df.columns):\n",
        "                missing = colonnes_requises - set(df.columns)\n",
        "                print(f\"‚ùå Colonnes manquantes dans {filename}: {missing}\")\n",
        "                return None\n",
        "\n",
        "            # Combinaison des textes\n",
        "            titre_resume = df[\"Titre\"].fillna(\"\") + \" \" + df[\"R√©sum√©\"].fillna(\"\")\n",
        "            entites_concat = df[\"Entities_bionlp\"].fillna(\"\") + \" \" + df[\"Entities_bc5cdr\"].fillna(\"\")\n",
        "\n",
        "            # D√©tection des virus\n",
        "            df[\"Virus_detect√©s\"] = [\n",
        "                \", \".join(sorted(detecter_virus(t1) | detecter_virus(t2)))\n",
        "                for t1, t2 in zip(titre_resume, entites_concat)\n",
        "            ]\n",
        "\n",
        "            # D√©tection des genres\n",
        "            df[\"Genus_detect√©s\"] = df[\"Virus_detect√©s\"].apply(\n",
        "                lambda viruses: \", \".join(sorted({\n",
        "                    dict_virus_genus.get(virus.strip(), \"\")\n",
        "                    for virus in viruses.split(\",\")\n",
        "                    if virus.strip() in dict_virus_genus\n",
        "                })) if pd.notna(viruses) else \"\"\n",
        "            )\n",
        "\n",
        "            # D√©tection des familles\n",
        "            df[\"Familles_detect√©es\"] = df[\"Genus_detect√©s\"].apply(\n",
        "                lambda genera: \", \".join(sorted({\n",
        "                    dict_genus_family.get(genus.strip(), \"\")\n",
        "                    for genus in genera.split(\",\")\n",
        "                    if genus.strip() in dict_genus_family\n",
        "                })) if pd.notna(genera) else \"\"\n",
        "            )\n",
        "\n",
        "            return df, filename\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erreur lors du traitement de {filepath}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    # üìÇ DOSSIER DE SORTIE\n",
        "    output_dir = \"fichiers_des_virus\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # üîÅ TRAITEMENT DES FICHIERS EN PARALL√àLE\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        futures = {executor.submit(traiter_fichier, filepath): filepath for filepath in excel_files}\n",
        "\n",
        "        for future in tqdm(concurrent.futures.as_completed(futures),\n",
        "                          total=len(futures),\n",
        "                          desc=\"üîÑ Traitement des fichiers\"):\n",
        "            result = future.result()\n",
        "            if result is not None:\n",
        "                df, filename = result\n",
        "                output_path = os.path.join(output_dir, filename)\n",
        "                df.to_excel(output_path, index=False, engine='openpyxl')\n",
        "                print(f\"‚úÖ Sauvegard√© : {output_path}\")\n",
        "\n",
        "    # üì¶ COMPRESSION EN FICHIER ZIP\n",
        "    zip_output_path = os.path.join(os.getcwd(), \"fichiers_virus_annot√©s\")\n",
        "    shutil.make_archive(zip_output_path, \"zip\", output_dir)\n",
        "\n",
        "    # üì§ T√âL√âCHARGEMENT DU ZIP\n",
        "    files.download(f\"{zip_output_path}.zip\")\n",
        "    print(f\"üì¶ Archive ZIP g√©n√©r√©e et pr√™te √† √™tre t√©l√©charg√©e: {zip_output_path}.zip\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "eNnKdHBtiQ2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìö IMPORTS\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "from flashtext import KeywordProcessor\n",
        "from tqdm import tqdm  # Barre de progression\n",
        "\n",
        "# üì• T√âL√âVERSEMENT DES FICHIERS\n",
        "print(\"‚û°Ô∏è T√©l√©versez le fichier ZIP contenant les fichiers .xlsx‚Ä¶\")\n",
        "zip_filename = list(files.upload().keys())[0]\n",
        "\n",
        "print(\"‚û°Ô∏è T√©l√©versez le fichier Excel des virus (colonnes: Virus, Variant)‚Ä¶\")\n",
        "virus_filename = list(files.upload().keys())[0]\n",
        "\n",
        "# üìÇ EXTRACTION DU ZIP\n",
        "input_dir = \"extracted_files\"\n",
        "os.makedirs(input_dir, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(input_dir)\n",
        "\n",
        "# üîç CHARGEMENT DES FICHIERS EXCEL\n",
        "excel_files = [\n",
        "    os.path.join(root, file)\n",
        "    for root, _, files_ in os.walk(input_dir)\n",
        "    for file in files_\n",
        "    if file.lower().endswith(\".xlsx\")\n",
        "]\n",
        "if not excel_files:\n",
        "    raise Exception(\"‚ùå Aucun fichier .xlsx trouv√© dans le dossier.\")\n",
        "\n",
        "# üìÑ LISTE DES VIRUS\n",
        "df_virus = pd.read_excel(virus_filename, engine='openpyxl')\n",
        "df_virus.columns = df_virus.columns.str.strip()\n",
        "\n",
        "# üß† DICTIONNAIRE DES VARIANTS\n",
        "dict_virus_variants = {\n",
        "    str(row.Virus).strip(): [\n",
        "        v.strip() for v in str(row.Variant).replace(\";\", \",\").split(\",\") if v.strip()\n",
        "    ]\n",
        "    for row in df_virus.itertuples(index=False)\n",
        "}\n",
        "\n",
        "# üîç INITIALISER FLASHTEXT\n",
        "kp = KeywordProcessor(case_sensitive=False)\n",
        "for virus, variants in dict_virus_variants.items():\n",
        "    for variant in variants:\n",
        "        kp.add_keyword(variant, virus)\n"
      ],
      "metadata": {
        "id": "USeozbRBpQJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0xvt3RUpOKa"
      },
      "outputs": [],
      "source": [
        "# ‚öôÔ∏è FONCTION DE D√âTECTION\n",
        "def detecter_virus_flashtext(texte):\n",
        "    return set(kp.extract_keywords(str(texte))) if pd.notna(texte) else set()\n",
        "\n",
        "# üìÇ DOSSIER DE SORTIE\n",
        "output_dir = \"fichier_des_virus\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# üîÅ TRAITEMENT DES FICHIERS\n",
        "for filepath in tqdm(excel_files, desc=\"üîÑ Traitement des fichiers\"):\n",
        "    filename = os.path.basename(filepath)\n",
        "    print(f\"üîé Traitement de : {filename}\")\n",
        "\n",
        "    df = pd.read_excel(filepath, engine='openpyxl')\n",
        "    colonnes_requises = {'Titre', 'R√©sum√©', 'Entities_bc5cdr', 'Entities_bionlp'}\n",
        "\n",
        "    if not colonnes_requises.issubset(df.columns):\n",
        "        print(f\"‚ùå Colonnes manquantes dans {filename}, ignor√©.\")\n",
        "        continue\n",
        "\n",
        "    # Combinaison vectoris√©e\n",
        "    titre_resume = df[\"Titre\"].astype(str) + \" \" + df[\"R√©sum√©\"].astype(str)\n",
        "    entites_concat = df[\"Entities_bionlp\"].astype(str) + \" \" + df[\"Entities_bc5cdr\"].astype(str)\n",
        "\n",
        "    # D√©tection avec boucle optimis√©e\n",
        "    df[\"Virus_detect√©s\"] = [\n",
        "        \"; \".join(sorted(detecter_virus_flashtext(t1).union(detecter_virus_flashtext(t2))))\n",
        "        for t1, t2 in zip(titre_resume, entites_concat)\n",
        "    ]\n",
        "\n",
        "    # üíæ Enregistrement\n",
        "    output_path = os.path.join(output_dir, filename)\n",
        "    df.to_excel(output_path, index=False)\n",
        "    print(f\"‚úÖ Sauvegard√© : {output_path}\")\n",
        "\n",
        "    # üì§ T√©l√©chargement sur Colab\n",
        "    files.download(output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil  # Pour compresser en ZIP\n",
        "\n",
        "# ‚öôÔ∏è FONCTION DE D√âTECTION\n",
        "def detecter_virus_flashtext(texte):\n",
        "    return set(kp.extract_keywords(str(texte))) if pd.notna(texte) else set()\n",
        "\n",
        "# üìÇ DOSSIER DE SORTIE\n",
        "output_dir = \"fichier_des_virus\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# üîÅ TRAITEMENT DES FICHIERS\n",
        "for filepath in tqdm(excel_files, desc=\"üîÑ Traitement des fichiers\"):\n",
        "    filename = os.path.basename(filepath)\n",
        "    print(f\"üîé Traitement de : {filename}\")\n",
        "\n",
        "    df = pd.read_excel(filepath, engine='openpyxl')\n",
        "    colonnes_requises = {'Titre', 'R√©sum√©', 'Entities_bc5cdr', 'Entities_bionlp'}\n",
        "\n",
        "    if not colonnes_requises.issubset(df.columns):\n",
        "        print(f\"‚ùå Colonnes manquantes dans {filename}, ignor√©.\")\n",
        "        continue\n",
        "\n",
        "    # Combinaison vectoris√©e\n",
        "    titre_resume = df[\"Titre\"].astype(str) + \" \" + df[\"R√©sum√©\"].astype(str)\n",
        "    entites_concat = df[\"Entities_bionlp\"].astype(str) + \" \" + df[\"Entities_bc5cdr\"].astype(str)\n",
        "\n",
        "    # D√©tection avec boucle optimis√©e\n",
        "    df[\"Virus_detect√©s\"] = [\n",
        "        \"; \".join(sorted(detecter_virus_flashtext(t1).union(detecter_virus_flashtext(t2))))\n",
        "        for t1, t2 in zip(titre_resume, entites_concat)\n",
        "    ]\n",
        "\n",
        "    # üíæ Enregistrement\n",
        "    output_path = os.path.join(output_dir, filename)\n",
        "    df.to_excel(output_path, index=False)\n",
        "    print(f\"‚úÖ Sauvegard√© : {output_path}\")\n",
        "\n",
        "# üì¶ COMPRESSION EN FICHIER ZIP\n",
        "zip_output_path = \"fichiers_virus_annot√©s.zip\"\n",
        "shutil.make_archive(base_name=\"fichiers_virus_annot√©s\", format=\"zip\", root_dir=output_dir)\n",
        "\n",
        "# üì§ T√âL√âCHARGEMENT DU ZIP\n",
        "files.download(zip_output_path)\n",
        "print(f\"üì¶ Archive ZIP g√©n√©r√©e et pr√™te √† √™tre t√©l√©charg√©e : {zip_output_path}\")\n"
      ],
      "metadata": {
        "id": "vApJSItAvpEj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}